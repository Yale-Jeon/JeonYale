{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa7645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bceb5",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec096c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train\\가구수정\\0.png</td>\n",
       "      <td>가구수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train\\가구수정\\1.png</td>\n",
       "      <td>가구수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train\\가구수정\\10.png</td>\n",
       "      <td>가구수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train\\가구수정\\11.png</td>\n",
       "      <td>가구수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train\\가구수정\\12.png</td>\n",
       "      <td>가구수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>./train\\훼손\\995.png</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>./train\\훼손\\996.png</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>./train\\훼손\\997.png</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>./train\\훼손\\998.png</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>./train\\훼손\\999.png</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4919 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 img_path label\n",
       "0      ./train\\가구수정\\0.png  가구수정\n",
       "1      ./train\\가구수정\\1.png  가구수정\n",
       "2     ./train\\가구수정\\10.png  가구수정\n",
       "3     ./train\\가구수정\\11.png  가구수정\n",
       "4     ./train\\가구수정\\12.png  가구수정\n",
       "...                   ...   ...\n",
       "4914   ./train\\훼손\\995.png    훼손\n",
       "4915   ./train\\훼손\\996.png    훼손\n",
       "4916   ./train\\훼손\\997.png    훼손\n",
       "4917   ./train\\훼손\\998.png    훼손\n",
       "4918   ./train\\훼손\\999.png    훼손\n",
       "\n",
       "[4919 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img_list = glob.glob('./train/*/*')\n",
    "\n",
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x : x.split('\\\\')[1])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0841c26",
   "metadata": {},
   "source": [
    "## Split train set and valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2b2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64e32b",
   "metadata": {},
   "source": [
    "## Label encoding\n",
    "\n",
    "19가지 하자유형을 숫자로 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c05a1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252     5\n",
       "2641    11\n",
       "4114    18\n",
       "1194     5\n",
       "2674    11\n",
       "        ..\n",
       "4767    18\n",
       "1950    10\n",
       "978      3\n",
       "2511    11\n",
       "684      3\n",
       "Name: label, Length: 3443, dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])\n",
    "\n",
    "train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b9349",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186457fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        image = np.array(image)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "            image = image.float()\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2131d4a",
   "metadata": {},
   "source": [
    "## Augmix\n",
    "\n",
    "모델의 Robustness를 향상시키기 위해 Random Augmix 기법을 도입하여 모든 이미지에 기본적으로 적용시켜 학습에 사용한다.\n",
    "\n",
    "### Augmix function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d1abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_parameter(level, maxval):\n",
    "    return int(level * maxval / 10)\n",
    "\n",
    "\n",
    "def float_parameter(level, maxval):\n",
    "    return float(level) * maxval / 10.\n",
    "\n",
    "\n",
    "def sample_level(n):\n",
    "    return np.random.uniform(low=0.1, high=n)\n",
    "\n",
    "\n",
    "def autocontrast(pil_img, _):\n",
    "    return ImageOps.autocontrast(pil_img)\n",
    "\n",
    "\n",
    "def equalize(pil_img, _):\n",
    "    return ImageOps.equalize(pil_img)\n",
    "\n",
    "\n",
    "def posterize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 4)\n",
    "    return ImageOps.posterize(pil_img, 4 - level)\n",
    "\n",
    "\n",
    "def rotate(pil_img, level):\n",
    "    degrees = int_parameter(sample_level(level), 30)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        degrees = -degrees\n",
    "    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def solarize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 256)\n",
    "    return ImageOps.solarize(pil_img, 256 - level)\n",
    "\n",
    "\n",
    "def shear_x(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size,\n",
    "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def shear_y(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size,\n",
    "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def translate_x(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size,\n",
    "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def translate_y(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size,\n",
    "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def color(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Color(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "def contrast(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Contrast(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "def brightness(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Brightness(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "def sharpness(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "augmentations = [\n",
    "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
    "    translate_x, translate_y\n",
    "]\n",
    "\n",
    "augmentations_all = [\n",
    "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
    "    translate_x, translate_y, color, contrast, brightness, sharpness\n",
    "]\n",
    "\n",
    "def normalize(image):\n",
    "    return image - 127\n",
    "\n",
    "def apply_op(image, op, severity):\n",
    "    pil_img = Image.fromarray(image)\n",
    "    pil_img = op(pil_img, severity)\n",
    "    return np.asarray(pil_img)\n",
    "\n",
    "def augment_and_mix(image, severity=3, width=3, depth=-1, alpha=1.):\n",
    "    ws = np.float32(np.random.dirichlet([alpha] * width))\n",
    "    m = np.float32(np.random.beta(alpha, alpha))\n",
    "\n",
    "    mix = np.zeros_like(image).astype(np.float32)\n",
    "    for i in range(width):\n",
    "        image_aug = image.copy()\n",
    "        depth = depth if depth > 0 else np.random.randint(1, 4)\n",
    "        for _ in range(depth):\n",
    "            op = np.random.choice(augmentations)\n",
    "            image_aug = apply_op(image_aug, op, severity)\n",
    "        mix += ws[i] * image_aug\n",
    "\n",
    "    mixed = (1 - m) * image + m * mix\n",
    "    return mixed\n",
    "\n",
    "class RandomAugMix(ImageOnlyTransform):\n",
    "\n",
    "    def __init__(self, severity=3, width=3, depth=-1, alpha=1., always_apply=False, p=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.severity = severity\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        image = augment_and_mix(\n",
    "            image,\n",
    "            self.severity,\n",
    "            self.width,\n",
    "            self.depth,\n",
    "            self.alpha\n",
    "        )\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b63143",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "모든 이미지의 사이즈를 224,224로 재설정하고 색상 값을 Normalize한다. Train set에는 위에서 정의한 RandomAugMix를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0490ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    RandomAugMix(severity=4, width=3, alpha=1.0, p=0.7),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False,\n",
    "                p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False,\n",
    "                p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4830d7",
   "metadata": {},
   "source": [
    "## Dataset and loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc0dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1da905",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "모델은 timm에서 제공하는 이미지 모델인 resnet18을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29087aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.model = timm.create_model('resnet18', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74618e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "179a8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    EPOCHS = 20\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    patience_check = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "        else:\n",
    "            if patience_check == 2:\n",
    "                break\n",
    "            else:\n",
    "                patience_check += 1\n",
    "\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(\n",
    "            f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb49dde",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ebfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            pred = model(imgs)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
    "\n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fb4cb",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1282dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c30ebffe08d40a7bf7da120ecb7ad96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaefabd2818d47bdb8279cca3a70722a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [2.23679] Val Loss : [1.68081] Val Weighted F1 Score : [0.39905]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7785dd2752437a8c92f285d441f2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50300776a1964673bd5b32b95da6642f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [1.45807] Val Loss : [1.17261] Val Weighted F1 Score : [0.57568]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fb52da770d4601859c945c4ca33278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccaf674c006344a597b425ea82ad973d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [1.04979] Val Loss : [0.91291] Val Weighted F1 Score : [0.68848]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30f483f0d984f518c1fde656ce1237d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb83a055526a483eac98137c53d08758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.78376] Val Loss : [0.74117] Val Weighted F1 Score : [0.76579]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c291dda4e2848e2b772eaacacb9aaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c740d037044681984daf7c49adabdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.56472] Val Loss : [0.59521] Val Weighted F1 Score : [0.81060]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02821a52b61d4ee99417b6b99ef81607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef03d7aeea164d838d78c07fecdbc9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.41897] Val Loss : [0.54196] Val Weighted F1 Score : [0.82268]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb12ca95d264e1dab2f1e6b93598eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af10898a3a543e4a800539cf55d6943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.32075] Val Loss : [0.47162] Val Weighted F1 Score : [0.84091]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf690384cb7a4a86a76d3e5b92d7cf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0525e3277a4d22b1df55b5ee3fdeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.25125] Val Loss : [0.47335] Val Weighted F1 Score : [0.84278]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9606d1a551a04e28be8e7e4fd610b58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c1d47193a349c398d95f6d721f123b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.20019] Val Loss : [0.45794] Val Weighted F1 Score : [0.85346]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da91f3f6c39d4df684f889a44efb8749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8088266869034775bab3d54bb33f38ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.16080] Val Loss : [0.46556] Val Weighted F1 Score : [0.85072]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee8fdfba7004a398d801237be2ac63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7080be803344309758abd9aab0f4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.14967] Val Loss : [0.48441] Val Weighted F1 Score : [0.85080]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddfe4db34054ca1982fd73d93748975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269daf46c0444d5cb65442a706fef5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.14641] Val Loss : [0.44220] Val Weighted F1 Score : [0.85794]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9961657cbf0241d59639d062c32b34b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1354cf17a5489fb1d2d9bf8bd8ed8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.11364] Val Loss : [0.46939] Val Weighted F1 Score : [0.86439]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545ae4e4aaff4e07bdfb91feb460f824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f90a7ca96a14a0b9aa4b6c290000200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c5412",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c06dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b37d83ff564da29faf0c16d9ff9a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds\n",
    "\n",
    "test = pd.read_csv('./test.csv')\n",
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "preds = inference(infer_model, test_loader, device)\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1923f795",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "cb492390",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "리더보드의 스코어는 f1 score이며 f1 score = 2 * ((Precision * Recall) / (Precision + Recall)) 이다.\n",
    "Precision는 True라고 분류한 것 중 실제 True인 것의 비율이며 Recall은 실제 True인 것 중 모델이 True라고 분류한 것의 비율이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac0c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
